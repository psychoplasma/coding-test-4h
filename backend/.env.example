# ==================== API Configuration ====================
API_V1_STR=/api
PROJECT_NAME="Multimodal Document Chat"

# ==================== Database ====================
# PostgreSQL with pgvector extension
# Format: postgresql+psycopg2://username:password@host:port/database
# Local development: postgresql+psycopg2://docuser:docpass@localhost:5432/docdb
DATABASE_URL=postgresql+psycopg2://docuser:docpass@localhost:5432/docdb

# ==================== Redis (Optional) ====================
# Used for caching and session management
# Local development: redis://localhost:6379/0
# Docker: redis://docling-redis:6379/0
REDIS_URL=redis://localhost:6379/0

# ==================== LLM Configuration ====================
# Choose between OpenAI or Google Gemini

# ----- OpenAI Configuration (RECOMMENDED FOR TESTING) -----
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# ----- Google Gemini Configuration (ALTERNATIVE) -----
# Use Gemini instead of OpenAI (set USE_GEMINI=True to enable)
USE_GEMINI=False
GEMINI_MODEL=gemini-2.5-flash-lite
GEMINI_EMBEDDING_MODEL=text-multilingual-embedding-002
GOOGLE_CLOUD_PROJECT=your-gcp-project-id
GOOGLE_CLOUD_PROJECT_LOCATION=us-central1

# Path to Google Cloud service account key JSON file
# Required if USE_GEMINI=True
# Download from: https://console.cloud.google.com/iam-admin/serviceaccounts
GOOGLE_APPLICATION_CREDENTIALS=./service-account-key.json

# ==================== LLM Settings ====================
# Maximum number of tokens for LLM output
LLM_MAX_OUTPUT_TOKENS=1024

# ==================== Upload Settings ====================
# Directory where uploaded files are stored
UPLOAD_DIR=./uploads

# Maximum file size in bytes (52428800 = 50 MB)
# Adjust based on your system resources
MAX_FILE_SIZE=52428800

# ==================== Vector Store Settings ====================
# Dimension of embeddings (max 384 for HuggingFace models)
# WARNING: Do not change after database creation - requires migration
EMBEDDING_DIMENSION=384

# Size of text chunks for processing
# Larger chunks = fewer embeddings but less granular search
# Typical range: 500-2000
CHUNK_SIZE=1000

# Overlap between chunks for context preservation
# Should be 10-20% of CHUNK_SIZE
CHUNK_OVERLAP=200

# Number of top results to retrieve in similarity search
# Typical range: 3-10
TOP_K_RESULTS=5

# ==================== Logging ====================
# Log format string
# Available fields: %(levelname)s, %(asctime)s, %(name)s, %(filename)s, %(lineno)d, %(message)s
LOG_FORMAT=[%(levelname)s] %(asctime)s [%(name)s] %(filename)s:%(lineno)d: %(message)s

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# DEBUG: Most verbose, includes all information
# INFO: Standard level, shows important events
# WARNING: Only shows warnings and errors
# ERROR: Only shows errors
# CRITICAL: Only shows critical errors
LOG_LEVEL=INFO
